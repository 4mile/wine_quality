{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.datalab.kernel\n",
    "\n",
    "import google.datalab.bigquery as bq\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create Tensorflow feature object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_feature_columns(input_features):\n",
    "  \"\"\"Construct the TensorFlow Feature Columns.\n",
    "\n",
    "  Args:\n",
    "    input_features: The names of the numerical input features to use.\n",
    "  Returns:\n",
    "    A set of feature columns\n",
    "  \"\"\" \n",
    "  return set([tf.feature_column.numeric_column(my_feature)\n",
    "              for my_feature in input_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\"Inputs data into TensorFlow object.\n",
    "  \n",
    "    Args:\n",
    "      features: pandas DataFrame of features\n",
    "      targets: pandas DataFrame of targets\n",
    "      batch_size: Size of batches to be passed to the model\n",
    "      shuffle: True or False. Whether to shuffle the data.\n",
    "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
    "    Returns:\n",
    "      Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                             \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get latest saved trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(features):\n",
    "  # Load the DNNRegressor object.\n",
    "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.000001)\n",
    "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "  dnn_regressor = tf.estimator.DNNRegressor(\n",
    "      feature_columns=construct_feature_columns(features),\n",
    "      hidden_units=[10, 10],\n",
    "      optimizer=my_optimizer,\n",
    "      model_dir='./models/wine_pred')\n",
    "\n",
    "  return dnn_regressor\n",
    "\n",
    "# dnn_regressor = get_model(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_values(features, dnn_regressor):\n",
    "  predict_training_input_fn = lambda: my_input_fn(features, \n",
    "                                                    targets = pd.DataFrame(index=range(len(features))),\n",
    "                                                    num_epochs=1, \n",
    "                                                    shuffle=False)\n",
    "\n",
    "  predictions = dnn_regressor.predict(input_fn=predict_training_input_fn)\n",
    "  predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class preparing data and defining features\n",
    "Data from Looker webhook should not have `quality`, but should have `wine_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewData():\n",
    "  \"\"\"\n",
    "  Feature creation, one-hot encoding of wine type, \n",
    "  removing unneeded fields, features dataframe and \n",
    "  wine id dataframe (to be mearged with predictions)\n",
    "  \n",
    "  Args:\n",
    "    Data from Looker\n",
    "  \n",
    "  Returns: \n",
    "    self.wine_id - Vector of wine ids to be joined with predictions\n",
    "    self.features - Dataframe of feature values for creating predictions\n",
    "  \n",
    "  \"\"\"\n",
    "  def __init__(self, df):\n",
    "      # Create vector of wine_ids\n",
    "      try:\n",
    "        self.wine_id = df[[\"wine_id\"]].copy()\n",
    "        df = df.drop(\"wine_id\", 1)\n",
    "        id_message = \"Wine_id found\"\n",
    "      except:\n",
    "        id_message = \"Warning, no wine_id\"\n",
    "      \n",
    "      # Drop target if it exists\n",
    "      try:\n",
    "        df = df.drop(\"quality\", 1)\n",
    "        target_message = \"Data contained target\"\n",
    "      except:\n",
    "        target_message = \"Data did NOT contain target\"\n",
    "        \n",
    "      # Drop date if it exists\n",
    "      try:\n",
    "        df = df.drop(\"created_at\", 1)\n",
    "        date_mess = \"Data contained created_at\"\n",
    "      except:\n",
    "        date_mess = \"Data did NOT contain created_at\"\n",
    "        \n",
    "      # Ordering fields (also checks for missing or extra fields)\n",
    "      try:\n",
    "        df = df[[\"wine_type\", \"fixed_acidity\", \"volatile_acidity\", \"citric_acid\", \"residual_sugar\", \"chlorides\", \"free_sulfur_dioxide\", \"total_sulfur_dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]]\n",
    "        order_mess = \"Fields Complete\"\n",
    "      except:\n",
    "        order_mess = \"Error: missing fields\"\n",
    "\n",
    "      # One-hot encoding for wine types\n",
    "      # Creates on variable, 1 for red and 0 for white\n",
    "      df = pd.get_dummies(df, columns=[\"wine_type\"])\n",
    "      \n",
    "      if \"wine_type_red\" in df:\n",
    "        red_wine_encoding_message = \"Contains red wine\"\n",
    "      else:\n",
    "        red_wine_encoding_message = \"No red wine\"\n",
    "        df[\"wine_type_red\"] = 0\n",
    "      \n",
    "      if \"wine_type_white\" in df:\n",
    "        white_wine_encoding_message = \"Contains white wine\"\n",
    "        df = df.drop(\"wine_type_white\", 1)\n",
    "      else:\n",
    "        white_wine_encoding_message = \"No white wine\"\n",
    "\n",
    "      # Checks for fixed_acidity = 0\n",
    "      # Change to neutral pH if 0\n",
    "      for i in range(len(df[\"fixed_acidity\"])):\n",
    "        if df.at[i, \"fixed_acidity\"] <= 0:\n",
    "          df.at[i,\"fixed_acidity\"] = 7\n",
    "      # Calculate sugar_to_acidity_ratio\n",
    "      df[\"sugar_to_acidity_ratio\"] = (\n",
    "        df[\"residual_sugar\"] /\n",
    "        df[\"fixed_acidity\"])\n",
    "      \n",
    "      # Final features variable\n",
    "      self.features = df.copy()\n",
    "\n",
    "      # Status messages\n",
    "      self.wine_id_mess = id_message\n",
    "      self.red_wine_mess = red_wine_encoding_message\n",
    "      self.white_wine_mess = white_wine_encoding_message\n",
    "      self.target_mess = target_message\n",
    "      self.order_mess = order_mess\n",
    "      self.date_mess = date_mess\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to write predictions back to Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_preds_to_bq(preds):\n",
    "  \"\"\"Writes predictions back to Bigquery.\n",
    "  Includes timestamp for deduping in db\n",
    "  \"\"\"\n",
    "  \n",
    "  # Specify GCP project and BQ dataset\n",
    "  client = bigquery.Client(project='looker-action-hub')\n",
    "  dataset_ref = client.dataset('wine_data')\n",
    "\n",
    "  # Define table\n",
    "  schema = [\n",
    "      bigquery.SchemaField('wine_id', 'INTEGER', mode='REQUIRED'),\n",
    "      bigquery.SchemaField('predicted_quality', 'FLOAT', mode='REQUIRED'),\n",
    "      bigquery.SchemaField('time', 'TIMESTAMP'),\n",
    "  ]\n",
    "  \n",
    "  table_ref = dataset_ref.table('predicted_quality')\n",
    "  table = bigquery.Table(table_ref, schema=schema)\n",
    "  \n",
    "  # Get current timestamp\n",
    "  import time\n",
    "  import datetime\n",
    "  ts = time.time()\n",
    "  ts = datetime.datetime.fromtimestamp(ts).isoformat()\n",
    "  preds[\"time\"] = ts\n",
    "  \n",
    "  # Writes new rows to table\n",
    "  try:\n",
    "    client.create_rows(table, preds.as_matrix())  # API request\n",
    "    rows_mess = \"Rows inserted in predicted_quality\"\n",
    "  except:\n",
    "    rows_mess = \"Error: problem inserting rows into predicted_quality\"\n",
    "    \n",
    "  return rows_mess\n",
    "\n",
    "  # If you ever need to recreate the table\n",
    "  # client.create_table(table)  # API request\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_predictions(data):\n",
    "  \"\"\"Final function\n",
    "  Args:\n",
    "    New data. (Currently taking Pandas dataframe, needs to be modified to take JSON from Looker when we know what form that will be.)\n",
    "    \n",
    "  Returns:\n",
    "    Writes predictions to back to Bigquery with wine_id to join back to wines and a timestamp of load for deduping\n",
    "  \"\"\"\n",
    "  \n",
    "  # Creates features to be put into model, and\n",
    "  # wine_id to be merged with predicted values\n",
    "  df = NewData(data)\n",
    "  print df.wine_id_mess\n",
    "  print df.red_wine_mess + \"; \" + df.white_wine_mess\n",
    "  print df.target_mess\n",
    "  print df.order_mess\n",
    "  print df.date_mess\n",
    "  \n",
    "  # Loads saved model from file\n",
    "  try:\n",
    "    dnn_regressor = get_model(df.features)\n",
    "    print \"Model loaded\"\n",
    "  except:\n",
    "    print \"Error loading model\"\n",
    "  \n",
    "  # Gets predicted values from new features and model\n",
    "  try:\n",
    "    predicted_values = pd.DataFrame(get_predicted_values(df.features, dnn_regressor))\n",
    "    predicted_values.columns = [\"predicted_quality\"]\n",
    "    print \"Predicted values produced\"\n",
    "  except:\n",
    "    print \"Error getting predicted values\"\n",
    "\n",
    "  # Merges predictions with wine_id\n",
    "  # Returns Pandas dataframe with wine_id and predicted values\n",
    "  predicted_values[\"wine_id\"] = df.wine_id\n",
    "  predicted_values = predicted_values[[\"wine_id\", \"predicted_quality\"]]\n",
    "  \n",
    "  # Writes predictions to Bigquery\n",
    "  mess = write_preds_to_bq(predicted_values)\n",
    "  print mess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data [Insert code getting new data from Looker webhook here]\n",
    "This will be replaced by code that accepts new data from Looker webhook.\n",
    "For now, we'll just pull it straight out of Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq query -n wine_query\n",
    "select *\n",
    "from `looker-action-hub.wine_data.new_wines_no_quality`\n",
    "where created_at > '2018-05-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://developers.google.com/accounts/docs/application-default-credentials.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5799a6638525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwine_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/datalab/bigquery/_query.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, output_options, sampling, context, query_params)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \"\"\"\n\u001b[1;32m    338\u001b[0m     return self.execute_async(output_options, sampling=sampling, context=context,\n\u001b[0;32m--> 339\u001b[0;31m                               query_params=query_params).wait()\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/datalab/bigquery/_query.pyc\u001b[0m in \u001b[0;36mexecute_async\u001b[0;34m(self, output_options, sampling, context, query_params)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0moverwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'overwrite'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0mtable_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/datalab/_context.pyc\u001b[0m in \u001b[0;36mdefault\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0mAn\u001b[0m \u001b[0minitialized\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshared\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mContext\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_project_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/datalab/utils/_utils.pyc\u001b[0m in \u001b[0;36mget_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No application credentials found. Perhaps you should sign in.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://developers.google.com/accounts/docs/application-default-credentials."
     ]
    }
   ],
   "source": [
    "features = wine_query.execute(output_options=bq.QueryOutput.dataframe()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
